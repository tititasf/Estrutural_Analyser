"""
Processador Multimodal para RAG Avan√ßado - AgenteCAD

Sistema preparado para processamento de m√∫ltiplas modalidades:
- Texto: Especifica√ß√µes CAD, coment√°rios, documenta√ß√£o
- Imagens: JPG/PNG de desenhos, capturas de interface
- DXF: Geometria estrutural, padr√µes de constru√ß√£o
- Machine Learning: Modelos treinados, vetores de features

Arquitetura preparada para integra√ß√£o futura com:
- CLIP para embeddings visuais
- Sentence Transformers para texto
- FAISS/Annoy para busca vetorial
- Transformers para gera√ß√£o
"""

import json
import logging
import hashlib
import base64
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np

logger = logging.getLogger(__name__)


class EmbeddingModel(Enum):
    """Modelos de embedding dispon√≠veis/preparados"""
    TEXT_SENTENCE_TRANSFORMERS = "sentence_transformers"
    TEXT_OPENAI_ADA = "openai_ada"
    VISION_CLIP = "clip"
    VISION_SIGLIP = "siglip"
    MULTIMODAL_CLIP = "clip_multimodal"


@dataclass
class ProcessedContent:
    """Conte√∫do processado com metadados"""
    original_content: Any
    modality_type: str
    processed_data: Dict[str, Any]
    embedding_vector: Optional[np.ndarray] = None
    embedding_model: Optional[EmbeddingModel] = None
    metadata: Dict[str, Any] = None
    processing_timestamp: datetime = None
    content_hash: str = None

    def __post_init__(self):
        if self.processing_timestamp is None:
            self.processing_timestamp = datetime.now()
        if self.content_hash is None:
            self.content_hash = self._generate_hash()
        if self.metadata is None:
            self.metadata = {}

    def _generate_hash(self) -> str:
        """Gerar hash √∫nico do conte√∫do"""
        content_str = str(self.original_content)
        if isinstance(self.original_content, bytes):
            content_str = base64.b64encode(self.original_content).decode()
        return hashlib.sha256(f"{content_str}{self.modality_type}".encode()).hexdigest()


class MultimodalVectorProcessor:
    """
    Processador Multimodal Principal

    Coordena processamento de diferentes modalidades e gera√ß√£o de embeddings
    preparados para RAG avan√ßado.
    """

    def __init__(self):
        self.processors = {
            'text': TextProcessor(),
            'image': ImageProcessor(),
            'dxf': DXFProcessor(),
            'ml_model': MLModelProcessor(),
            'structural_pattern': StructuralPatternProcessor()
        }

        # Cache de embeddings processados
        self.embedding_cache = {}
        self.cache_ttl_hours = 24

        # Estat√≠sticas de processamento
        self.stats = {
            'processed_items': 0,
            'cache_hits': 0,
            'embedding_generations': 0,
            'errors': 0
        }

        logger.info("üé® Processador Multimodal inicializado")

    def process_content(self, content: Any, modality: str,
                       generate_embedding: bool = True) -> ProcessedContent:
        """
        Processar conte√∫do multimodal

        Args:
            content: Conte√∫do a processar
            modality: Tipo de modalidade ('text', 'image', 'dxf', etc.)
            generate_embedding: Se deve gerar embedding vetorial

        Returns:
            ProcessedContent: Conte√∫do processado com metadados
        """
        try:
            # Verificar cache
            content_hash = self._generate_content_hash(content, modality)
            if content_hash in self.embedding_cache:
                cached = self.embedding_cache[content_hash]
                if self._is_cache_valid(cached):
                    self.stats['cache_hits'] += 1
                    return cached

            # Processar com processador espec√≠fico
            processor = self.processors.get(modality, GenericProcessor())
            processed_data = processor.process(content)

            # Gerar embedding se solicitado
            embedding_vector = None
            embedding_model = None

            if generate_embedding:
                embedding_vector, embedding_model = self._generate_embedding(
                    processed_data, modality
                )

            # Criar resultado processado
            result = ProcessedContent(
                original_content=content,
                modality_type=modality,
                processed_data=processed_data,
                embedding_vector=embedding_vector,
                embedding_model=embedding_model,
                metadata={
                    'processing_success': True,
                    'embedding_generated': embedding_vector is not None
                }
            )

            # Cache do resultado
            self.embedding_cache[content_hash] = result

            self.stats['processed_items'] += 1
            if embedding_vector is not None:
                self.stats['embedding_generations'] += 1

            return result

        except Exception as e:
            logger.error(f"Erro no processamento multimodal: {e}")
            self.stats['errors'] += 1

            # Retornar resultado de erro
            return ProcessedContent(
                original_content=content,
                modality_type=modality,
                processed_data={'error': str(e)},
                metadata={'processing_success': False, 'error': str(e)}
            )

    def search_similar(self, query_content: ProcessedContent,
                      search_space: List[ProcessedContent],
                      top_k: int = 5) -> List[Tuple[ProcessedContent, float]]:
        """
        Buscar conte√∫do similar usando embeddings

        Args:
            query_content: Conte√∫do de consulta
            search_space: Espa√ßo de busca
            top_k: N√∫mero de resultados

        Returns:
            List[Tuple[ProcessedContent, float]]: Resultados com similaridade
        """
        if query_content.embedding_vector is None:
            return []

        results = []

        for item in search_space:
            if item.embedding_vector is not None:
                # Calcular similaridade coseno
                similarity = self._cosine_similarity(
                    query_content.embedding_vector,
                    item.embedding_vector
                )
                results.append((item, similarity))

        # Ordenar por similaridade decrescente
        results.sort(key=lambda x: x[1], reverse=True)

        return results[:top_k]

    def _generate_embedding(self, processed_data: Dict[str, Any],
                           modality: str) -> Tuple[Optional[np.ndarray], Optional[EmbeddingModel]]:
        """
        Gerar embedding vetorial (placeholder para implementa√ß√£o futura)

        TODO: Implementar integra√ß√£o com:
        - sentence-transformers para texto
        - CLIP para imagens
        - Modelos customizados para DXF/ML
        """
        try:
            # Placeholder: gerar embedding aleat√≥rio para demonstra√ß√£o
            # TODO: Substituir por modelos reais
            if modality == 'text':
                # Simular embedding de texto (768 dimens√µes t√≠pico)
                embedding = np.random.normal(0, 1, 768)
                model = EmbeddingModel.TEXT_SENTENCE_TRANSFORMERS
            elif modality == 'image':
                # Simular embedding visual (512 dimens√µes t√≠pico)
                embedding = np.random.normal(0, 1, 512)
                model = EmbeddingModel.VISION_CLIP
            elif modality == 'dxf':
                # Simular embedding geom√©trico
                embedding = np.random.normal(0, 1, 256)
                model = EmbeddingModel.TEXT_SENTENCE_TRANSFORMERS  # Usar texto por enquanto
            else:
                # Embedding gen√©rico
                embedding = np.random.normal(0, 1, 128)
                model = EmbeddingModel.TEXT_SENTENCE_TRANSFORMERS

            # Normalizar
            embedding = embedding / np.linalg.norm(embedding)

            return embedding, model

        except Exception as e:
            logger.warning(f"Erro na gera√ß√£o de embedding: {e}")
            return None, None

    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calcular similaridade coseno"""
        try:
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            return dot_product / (norm1 * norm2)
        except:
            return 0.0

    def _generate_content_hash(self, content: Any, modality: str) -> str:
        """Gerar hash √∫nico para cache"""
        content_str = str(content)
        if isinstance(content, bytes):
            content_str = base64.b64encode(content).decode()
        return hashlib.md5(f"{content_str}{modality}".encode()).hexdigest()

    def _is_cache_valid(self, cached_item: ProcessedContent) -> bool:
        """Verificar se item em cache ainda √© v√°lido"""
        if cached_item.processing_timestamp is None:
            return False

        hours_old = (datetime.now() - cached_item.processing_timestamp).total_seconds() / 3600
        return hours_old < self.cache_ttl_hours

    def get_stats(self) -> Dict[str, Any]:
        """Retornar estat√≠sticas do processador"""
        return dict(self.stats)

    def clear_cache(self) -> None:
        """Limpar cache de embeddings"""
        self.embedding_cache.clear()
        logger.info("üßπ Cache de embeddings limpo")


class TextProcessor:
    """Processador de Texto - Preparado para an√°lise sem√¢ntica"""

    def process(self, content: str) -> Dict[str, Any]:
        """
        Processar texto para extra√ß√£o de features

        TODO: Implementar:
        - Named Entity Recognition (NER)
        - Topic modeling
        - Sentiment analysis
        - Language detection
        """
        return {
            'text': content,
            'length': len(content),
            'word_count': len(content.split()),
            'language': 'pt',  # TODO: Detectar idioma
            'entities': [],    # TODO: Extrair entidades
            'topics': [],      # TODO: Identificar t√≥picos
            'sentiment': 0.0,  # TODO: An√°lise de sentimento
            'keywords': [],    # TODO: Extrair palavras-chave
            'readability_score': 0.0  # TODO: Score de legibilidade
        }


class ImageProcessor:
    """Processador de Imagens - Preparado para vis√£o computacional"""

    def process(self, content: Union[str, bytes]) -> Dict[str, Any]:
        """
        Processar imagem para extra√ß√£o de features visuais

        TODO: Implementar:
        - OCR (Optical Character Recognition)
        - Object detection
        - Feature extraction (CNN)
        - Image classification
        - Metadata extraction
        """
        try:
            # Se for path, ler arquivo
            if isinstance(content, str):
                with open(content, 'rb') as f:
                    image_data = f.read()
            else:
                image_data = content

            return {
                'image_data': image_data,
                'size_bytes': len(image_data),
                'ocr_text': '',        # TODO: Implementar OCR
                'objects_detected': [], # TODO: Object detection
                'dominant_colors': [],  # TODO: Extra√ß√£o de cores
                'image_features': [],   # TODO: CNN features
                'dimensions': None,     # TODO: Extrair dimens√µes
                'format': 'unknown'     # TODO: Detectar formato
            }

        except Exception as e:
            return {
                'error': f'Erro no processamento de imagem: {e}',
                'image_data': None
            }


class DXFProcessor:
    """Processador de DXF - An√°lise geom√©trica estrutural"""

    def process(self, content: Any) -> Dict[str, Any]:
        """
        Processar arquivo DXF para extra√ß√£o de geometria

        TODO: Implementar:
        - Parsing de entidades DXF
        - An√°lise de geometria (√°reas, volumes)
        - Detec√ß√£o de padr√µes estruturais
        - Valida√ß√£o de conformidade
        - Extra√ß√£o de metadados
        """
        try:
            # Placeholder para processamento DXF
            # TODO: Integrar com ezdxf ou biblioteca similar

            return {
                'entities_count': 0,      # TODO: Contar entidades
                'layers': [],             # TODO: Listar layers
                'bounds': None,           # TODO: Calcular bounding box
                'geometry_types': [],     # TODO: Tipos de geometria
                'complexity_score': 0.0,  # TODO: Score de complexidade
                'structural_patterns': [], # TODO: Padr√µes estruturais
                'validation_errors': [],   # TODO: Erros de valida√ß√£o
                'metadata': {}            # TODO: Metadados do arquivo
            }

        except Exception as e:
            return {
                'error': f'Erro no processamento DXF: {e}',
                'entities_count': 0
            }


class MLModelProcessor:
    """Processador de Modelos de Machine Learning"""

    def process(self, content: Any) -> Dict[str, Any]:
        """
        Processar modelo de ML para extra√ß√£o de metadados

        TODO: Implementar:
        - Detec√ß√£o de arquitetura
        - Contagem de par√¢metros
        - M√©tricas de performance
        - Feature importance
        - An√°lise de overfitting
        """
        try:
            return {
                'model_type': 'unknown',     # TODO: Detectar tipo
                'architecture': 'unknown',   # TODO: Analisar arquitetura
                'parameters_count': 0,       # TODO: Contar par√¢metros
                'input_shape': None,         # TODO: Shape de entrada
                'output_shape': None,        # TODO: Shape de sa√≠da
                'performance_metrics': {},   # TODO: M√©tricas
                'training_history': [],      # TODO: Hist√≥rico de treinamento
                'feature_importance': [],    # TODO: Import√¢ncia de features
                'model_size_bytes': 0        # TODO: Tamanho do modelo
            }

        except Exception as e:
            return {
                'error': f'Erro no processamento de modelo ML: {e}',
                'model_type': 'error'
            }


class StructuralPatternProcessor:
    """Processador de Padr√µes Estruturais"""

    def process(self, content: Any) -> Dict[str, Any]:
        """
        Processar padr√µes estruturais CAD

        TODO: Implementar:
        - Detec√ß√£o de padr√µes de viga
        - An√°lise de lajes
        - Padr√µes de pilares
        - Regras de constru√ß√£o
        - Valida√ß√£o estrutural
        """
        try:
            return {
                'pattern_type': 'unknown',      # TODO: Classificar padr√£o
                'confidence_score': 0.0,        # TODO: Score de confian√ßa
                'structural_elements': [],      # TODO: Elementos estruturais
                'dimensional_analysis': {},     # TODO: An√°lise dimensional
                'material_properties': {},      # TODO: Propriedades materiais
                'load_analysis': {},           # TODO: An√°lise de cargas
                'compliance_checks': [],       # TODO: Verifica√ß√µes de conformidade
                'recommendations': []          # TODO: Recomenda√ß√µes
            }

        except Exception as e:
            return {
                'error': f'Erro no processamento de padr√£o estrutural: {e}',
                'pattern_type': 'error'
            }


class GenericProcessor:
    """Processador gen√©rico para modalidades n√£o espec√≠ficas"""

    def process(self, content: Any) -> Dict[str, Any]:
        """Processamento b√°sico gen√©rico"""
        return {
            'content_type': str(type(content)),
            'size': len(str(content)) if content else 0,
            'processed': False,
            'note': 'Processamento gen√©rico - modalidade n√£o espec√≠fica'
        }


# Fun√ß√µes utilit√°rias para integra√ß√£o
def create_multimodal_index(processed_items: List[ProcessedContent]) -> Dict[str, Any]:
    """
    Criar √≠ndice multimodal para busca eficiente

    Args:
        processed_items: Lista de itens processados

    Returns:
        Dict com √≠ndice estruturado
    """
    index = {
        'text_items': [],
        'image_items': [],
        'dxf_items': [],
        'ml_items': [],
        'structural_items': [],
        'embeddings_matrix': None,
        'metadata': {
            'total_items': len(processed_items),
            'created_at': datetime.now(),
            'modalities_count': {}
        }
    }

    # Organizar por modalidade
    embeddings_list = []

    for item in processed_items:
        modality_list = f"{item.modality_type}_items"
        if modality_list in index:
            index[modality_list].append(item)

        # Contar modalidades
        mod_count = index['metadata']['modalities_count']
        mod_count[item.modality_type] = mod_count.get(item.modality_type, 0) + 1

        # Coletar embeddings
        if item.embedding_vector is not None:
            embeddings_list.append(item.embedding_vector)

    # Criar matriz de embeddings se houver
    if embeddings_list:
        index['embeddings_matrix'] = np.array(embeddings_list)

    return index


def search_multimodal_index(query: ProcessedContent,
                           index: Dict[str, Any],
                           top_k: int = 5) -> List[Tuple[ProcessedContent, float]]:
    """
    Buscar no √≠ndice multimodal

    Args:
        query: Item de consulta processado
        index: √çndice multimodal
        top_k: N√∫mero de resultados

    Returns:
        Lista de tuplas (item, similaridade)
    """
    if query.embedding_vector is None or index['embeddings_matrix'] is None:
        return []

    # Busca vetorial simples (TODO: Otimizar com FAISS/Annoy)
    similarities = []

    for i, item in enumerate(index[f"{query.modality_type}_items"]):
        if item.embedding_vector is not None:
            # Calcular similaridade coseno
            similarity = np.dot(query.embedding_vector, item.embedding_vector) / (
                np.linalg.norm(query.embedding_vector) * np.linalg.norm(item.embedding_vector)
            )
            similarities.append((item, similarity))

    # Ordenar e retornar top-k
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]


# Placeholder para futuras bibliotecas recomendadas
RECOMMENDED_LIBRARIES = {
    'text_processing': [
        'sentence-transformers>=2.2.0',
        'transformers>=4.21.0',
        'spacy>=3.5.0',
        'nltk>=3.8.0'
    ],
    'image_processing': [
        'Pillow>=9.0.0',
        'opencv-python>=4.7.0',
        'torch>=1.13.0',
        'torchvision>=0.14.0'
    ],
    'dxf_processing': [
        'ezdxf>=1.1.0',
        'shapely>=2.0.0',
        'trimesh>=3.20.0'
    ],
    'vector_search': [
        'faiss-cpu>=1.7.0',
        'annoy>=1.17.0',
        'scikit-learn>=1.2.0'
    ],
    'ml_models': [
        'scikit-learn>=1.2.0',
        'xgboost>=1.7.0',
        'lightgbm>=3.3.0'
    ]
}